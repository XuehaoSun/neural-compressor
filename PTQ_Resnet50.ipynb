{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial demonstrates how to perform post training quantization (PTQ) on a [Resnet50](https://github.com/onnx/models/raw/main/vision/classification/resnet/) model.\n",
    "\n",
    "## Prerequisite\n",
    "\n",
    "### 1. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install neural-compressor onnx onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/onnx/models/raw/main/vision/classification/resnet/model/resnet50-v1-12.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Dataset\n",
    "\n",
    "Get granted and download ILSVRC2012 dataset from https://image-net.org/signup.php\n",
    "\n",
    "Download label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz\n",
    "!tar -xvzf caffe_ilsvrc12.tar.gz val.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import collections\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def collate(batch):\n",
    "    \"\"\"Puts each data field into a pd frame with outer dimension batch size\"\"\"\n",
    "    elem = batch[0]\n",
    "    if isinstance(elem, collections.abc.Mapping):\n",
    "        return {key: collate([d[key] for d in batch]) for key in elem}\n",
    "    elif isinstance(elem, collections.abc.Sequence):\n",
    "        batch = zip(*batch)\n",
    "        return [collate(samples) for samples in batch]\n",
    "    elif isinstance(elem, np.ndarray):\n",
    "        try:\n",
    "            return np.stack(batch)\n",
    "        except:\n",
    "            return batch\n",
    "    else:\n",
    "        return batch\n",
    "\n",
    "class Dataloader:\n",
    "    def __init__(self, dataset_location, image_list, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.image_list = []\n",
    "        self.label_list = []\n",
    "        with open(image_list, 'r') as f:\n",
    "            for s in f:\n",
    "                image_name, label = re.split(r\"\\s+\", s.strip())\n",
    "                src = os.path.join(dataset_location, image_name)\n",
    "                if not os.path.exists(src):\n",
    "                    continue\n",
    "\n",
    "                self.image_list.append(src)\n",
    "                self.label_list.append(int(label))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self._generate_dataloader()\n",
    "\n",
    "    def _generate_dataloader(self):\n",
    "        sampler = iter(range(0, len(self.image_list), 1))\n",
    "        \n",
    "        def batch_sampler():\n",
    "            batch = []\n",
    "            for idx in sampler:\n",
    "                batch.append(idx)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch = []\n",
    "            if len(batch) > 0:\n",
    "                yield batch\n",
    "\n",
    "        def fetcher(ids):\n",
    "            data = [self._preprpcess(self.image_list[idx]) for idx in ids]\n",
    "            label = [self.label_list[idx] for idx in ids]\n",
    "            return collate(data), label\n",
    "\n",
    "        for batched_indices in batch_sampler():\n",
    "            try:\n",
    "                data = fetcher(batched_indices)\n",
    "                yield data\n",
    "            except StopIteration:\n",
    "                return\n",
    "    \n",
    "    def _preprpcess(self, src):\n",
    "        with Image.open(src) as image:\n",
    "            image = np.array(image.convert('RGB'), dtype='float32')\n",
    "            image /= 255.\n",
    "\n",
    "            # resize\n",
    "            image = cv2.resize(image, (256, 256))\n",
    "            if len(image.shape) == 2:\n",
    "                image = np.expand_dims(image, -1)\n",
    "            \n",
    "            # center crop\n",
    "            h, w = image.shape[0], image.shape[1]\n",
    "            if h < 224 or w < 224:\n",
    "                raise ValueError(\n",
    "                    \"Required crop size (224, 224) is larger then input image size {}\".format((h, w)))\n",
    "            elif h > 224 or w > 224:\n",
    "                y0 = (h - 224) // 2\n",
    "                x0 = (w - 224) // 2\n",
    "                image = image[y0:y0 + 224, x0:x0 + 224, :]\n",
    "\n",
    "            # normalize\n",
    "            image = (image - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
    "\n",
    "            # transpose\n",
    "            image = image.transpose((2, 0, 1))\n",
    "            return image.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def _topk_shape_validate(preds, labels):\n",
    "    # preds shape can be Nxclass_num or class_num(N=1 by default)\n",
    "    preds = np.array(preds)\n",
    "    labels = np.array(labels)\n",
    "    labels = labels.reshape((labels.shape[0], 1))\n",
    "\n",
    "    N = preds.shape[0]\n",
    "    preds = preds.reshape([N, -1])\n",
    "    class_num = preds.shape[1]\n",
    "\n",
    "    label_N = labels.shape[0]\n",
    "    assert label_N == N, 'labels batch size should same with preds'\n",
    "    labels = labels.reshape([N, -1])\n",
    "    # one-hot labels will have 2 dimension not equal 1\n",
    "    if labels.shape[1] != 1:\n",
    "        labels = labels.argsort()[..., -1:]\n",
    "    return preds, labels\n",
    "\n",
    "class TopK:\n",
    "    def __init__(self, k=1):\n",
    "        self.k = k\n",
    "        self.num_correct = 0\n",
    "        self.num_sample = 0\n",
    "\n",
    "    def update(self, preds, labels):\n",
    "        preds, labels = _topk_shape_validate(preds, labels)\n",
    "        preds = preds.argsort()[..., -self.k:]\n",
    "        if self.k == 1:\n",
    "            correct = accuracy_score(preds, labels, normalize=False)\n",
    "            self.num_correct += correct\n",
    "        else:\n",
    "            for p, l in zip(preds, labels):\n",
    "                # get top-k labels with np.argpartition\n",
    "                # p = np.argpartition(p, -self.k)[-self.k:]\n",
    "                l = l.astype('int32')\n",
    "                if l in p:\n",
    "                    self.num_correct += 1\n",
    "        self.num_sample += len(labels)\n",
    "\n",
    "    def reset(self):\n",
    "        self.num_correct = 0\n",
    "        self.num_sample = 0\n",
    "\n",
    "    def result(self):\n",
    "        if self.num_sample == 0:\n",
    "            print(\"Sample num during evaluation is 0.\")\n",
    "            return 0\n",
    "        return self.num_correct / self.num_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "\n",
    "import onnxruntime as ort\n",
    "\n",
    "def eval_func(model, dataloader, metric):\n",
    "    metric.reset()\n",
    "    sess = ort.InferenceSession(model.SerializeToString(), providers=ort.get_available_providers())\n",
    "    input_names = [i.name for i in sess.get_inputs()]\n",
    "    for input_data, label in dataloader:\n",
    "        output = sess.run(None, dict(zip(input_names, [input_data])))\n",
    "        metric.update(output, label)\n",
    "    return metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 20:12:41 [WARNING] Force convert framework model to neural_compressor model.\n",
      "2023-02-14 20:12:47 [INFO] Get FP32 model baseline.\n",
      "2023-02-14 20:12:48 [INFO] Save tuning history to /home/mengniwa/notebook/nc_workspace/2023-02-14_19-55-18/./history.snapshot.\n",
      "2023-02-14 20:12:48 [INFO] FP32 baseline is: [Accuracy: 0.7250, Duration (seconds): 1.0148]\n",
      "2023-02-14 20:13:05 [INFO] |******Mixed Precision Statistics******|\n",
      "2023-02-14 20:13:05 [INFO] +---------------------+-------+--------+\n",
      "2023-02-14 20:13:05 [INFO] |       Op Type       | Total |  INT8  |\n",
      "2023-02-14 20:13:05 [INFO] +---------------------+-------+--------+\n",
      "2023-02-14 20:13:05 [INFO] |         Conv        |   53  |   53   |\n",
      "2023-02-14 20:13:05 [INFO] |        MatMul       |   1   |   1    |\n",
      "2023-02-14 20:13:05 [INFO] |       MaxPool       |   1   |   1    |\n",
      "2023-02-14 20:13:05 [INFO] |  GlobalAveragePool  |   1   |   1    |\n",
      "2023-02-14 20:13:05 [INFO] |         Add         |   17  |   17   |\n",
      "2023-02-14 20:13:05 [INFO] |    QuantizeLinear   |   2   |   2    |\n",
      "2023-02-14 20:13:05 [INFO] |   DequantizeLinear  |   2   |   2    |\n",
      "2023-02-14 20:13:05 [INFO] +---------------------+-------+--------+\n",
      "2023-02-14 20:13:05 [INFO] Pass quantize model elapsed time: 16748.94 ms\n",
      "2023-02-14 20:13:05 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 0.7500|0.7250, Duration (seconds) (int8|fp32): 0.6608|1.0148], Best tune result is: [Accuracy: 0.7500, Duration (seconds): 0.6608]\n",
      "2023-02-14 20:13:05 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2023-02-14 20:13:05 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2023-02-14 20:13:05 [INFO] |     Info Type      | Baseline | Tune 1 result | Best tune result |\n",
      "2023-02-14 20:13:05 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2023-02-14 20:13:05 [INFO] |      Accuracy      | 0.7250   |    0.7500     |     0.7500       |\n",
      "2023-02-14 20:13:05 [INFO] | Duration (seconds) | 1.0148   |    0.6608     |     0.6608       |\n",
      "2023-02-14 20:13:05 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2023-02-14 20:13:05 [INFO] Save tuning history to /home/mengniwa/notebook/nc_workspace/2023-02-14_19-55-18/./history.snapshot.\n",
      "2023-02-14 20:13:05 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2023-02-14 20:13:05 [INFO] Save deploy yaml to /home/mengniwa/notebook/nc_workspace/2023-02-14_19-55-18/deploy.yaml\n"
     ]
    }
   ],
   "source": [
    "# launcher code\n",
    "\n",
    "import onnx\n",
    "from neural_compressor import quantization, PostTrainingQuantConfig\n",
    "\n",
    "model = onnx.load('./resnet50-v1-12.onnx')\n",
    "data_path = '/path/to/ILSVRC2012_img_val'\n",
    "label_path = '/path/to/val.txt'\n",
    "batch_size = 1\n",
    "dataloader = Dataloader(data_path, label_path, batch_size)\n",
    "top1 = TopK()\n",
    "\n",
    "def eval(onnx_model):\n",
    "    return eval_func(onnx_model, dataloader, top1)\n",
    "\n",
    "config = PostTrainingQuantConfig()\n",
    "q_model = quantization.fit(model, config, calib_dataloader=dataloader,\n",
    "\t     eval_func=eval)\n",
    "q_model.save('./resnet50-int8.onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
