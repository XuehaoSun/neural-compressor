{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial demonstrates how to perform post training quantization (PTQ) on a [bert-base]() model.\n",
    "\n",
    "## Prerequisite\n",
    "\n",
    "### 1. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neural-compressor in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (2.0)\n",
      "Requirement already satisfied: onnx in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (1.13.0)\n",
      "Requirement already satisfied: onnxruntime in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (1.14.0)\n",
      "Requirement already satisfied: tensorflow in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (2.9.0)\n",
      "Requirement already satisfied: pandas in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (1.5.3)\n",
      "Requirement already satisfied: numpy in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (1.24.2)\n",
      "Requirement already satisfied: requests in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (2.28.2)\n",
      "Requirement already satisfied: schema in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (0.7.5)\n",
      "Requirement already satisfied: Pillow in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (9.4.0)\n",
      "Requirement already satisfied: scikit-learn in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (1.2.1)\n",
      "Requirement already satisfied: pycocotools in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (2.0.6)\n",
      "Requirement already satisfied: pyyaml in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (6.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (9.0.0)\n",
      "Requirement already satisfied: prettytable in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (3.6.0)\n",
      "Requirement already satisfied: opencv-python in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (4.7.0.68)\n",
      "Requirement already satisfied: deprecated in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (1.2.13)\n",
      "Requirement already satisfied: psutil in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from neural-compressor) (5.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from onnx) (4.4.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from onnx) (3.20.3)\n",
      "Requirement already satisfied: coloredlogs in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: sympy in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from onnxruntime) (1.11.1)\n",
      "Requirement already satisfied: packaging in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from onnxruntime) (23.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (0.30.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: setuptools in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (67.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from requests->neural-compressor) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from requests->neural-compressor) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from requests->neural-compressor) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from requests->neural-compressor) (1.26.14)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from pandas->neural-compressor) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from pandas->neural-compressor) (2022.7.1)\n",
      "Requirement already satisfied: wcwidth in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from prettytable->neural-compressor) (0.2.6)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from pycocotools->neural-compressor) (3.6.3)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from schema->neural-compressor) (21.6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from scikit-learn->neural-compressor) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from scikit-learn->neural-compressor) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from scikit-learn->neural-compressor) (1.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from sympy->onnxruntime) (1.2.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor) (0.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/mengniwa/miniconda3/envs/book/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install neural-compressor onnx onnxruntime torch tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-16 10:34:53--  https://github.com/onnx/models/raw/main/text/machine_comprehension/bert-squad/model/bertsquad-12.onnx\n",
      "Resolving proxy-prc.intel.com (proxy-prc.intel.com)... 10.240.252.16\n",
      "Connecting to proxy-prc.intel.com (proxy-prc.intel.com)|10.240.252.16|:913... connected.\n",
      "Proxy request sent, awaiting response... 302 Found\n",
      "Location: https://media.githubusercontent.com/media/onnx/models/main/text/machine_comprehension/bert-squad/model/bertsquad-12.onnx [following]\n",
      "--2023-02-16 10:34:54--  https://media.githubusercontent.com/media/onnx/models/main/text/machine_comprehension/bert-squad/model/bertsquad-12.onnx\n",
      "Connecting to proxy-prc.intel.com (proxy-prc.intel.com)|10.240.252.16|:913... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 435852736 (416M) [application/octet-stream]\n",
      "Saving to: ‘bertsquad-12.onnx’\n",
      "\n",
      "100%[======================================>] 435,852,736 11.8MB/s   in 34s    \n",
      "\n",
      "2023-02-16 10:35:39 (12.2 MB/s) - ‘bertsquad-12.onnx’ saved [435852736/435852736]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/onnx/models/raw/main/text/machine_comprehension/bert-squad/model/bertsquad-12.onnx\n",
    "!wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!unzip uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-17 13:16:52--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
      "Resolving proxy-prc.intel.com (proxy-prc.intel.com)... 10.240.252.16\n",
      "Connecting to proxy-prc.intel.com (proxy-prc.intel.com)|10.240.252.16|:913... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 4854279 (4.6M) [application/json]\n",
      "Saving to: ‘dev-v1.1.json’\n",
      "\n",
      "100%[======================================>] 4,854,279   3.19MB/s   in 1.5s   \n",
      "\n",
      "2023-02-17 13:16:54 (3.19 MB/s) - ‘dev-v1.1.json’ saved [4854279/4854279]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 13:18:05.251540: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-17 13:18:06.065974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-17 13:18:06.065997: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import onnx\n",
    "import tokenization\n",
    "import os\n",
    "from run_onnx_squad import *\n",
    "import json\n",
    "from run_onnx_squad import read_squad_examples, convert_examples_to_features, write_predictions\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "from squad_evaluate import evaluate\n",
    "import sys\n",
    "\n",
    "max_seq_length = 256\n",
    "doc_stride = 128\n",
    "max_query_length = 64\n",
    "n_best_size = 20\n",
    "max_answer_length = 30\n",
    "\n",
    "class squadDataset(Dataset):\n",
    "    def __init__(self, unique_ids, input_ids, input_mask, segment_ids, bs):\n",
    "        self.unique_ids = unique_ids\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.bs = bs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (list(range(index, index + self.bs)), self.input_ids[index:index + self.bs][0].astype(np.int64), \n",
    "            self.input_mask[index:index + self.bs][0].astype(np.int64), self.segment_ids[index:index + self.bs][0].astype(np.int64)), 0\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.input_ids) == len(self.input_mask)\n",
    "        assert len(self.input_ids) == len(self.segment_ids)\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "\n",
    "def evaluate_squad(model, dataloader, input_ids, eval_examples, extra_data, input_file):\n",
    "    session = onnxruntime.InferenceSession(model.SerializeToString(), None,\n",
    "        providers=onnxruntime.get_available_providers())\n",
    "    for output_meta in session.get_outputs():\n",
    "        print(output_meta)\n",
    "    for input_meta in session.get_inputs():\n",
    "        print(input_meta)\n",
    "    n = len(input_ids)\n",
    "    bs = 1\n",
    "    all_results = []\n",
    "    start = timer()\n",
    "    for idx, (batch, label) in tqdm.tqdm(enumerate(dataloader), desc=\"eval\"):\n",
    "        data = {\"unique_ids_raw_output___9:0\": np.array(batch[0], dtype=np.int64),\n",
    "                \"input_ids:0\": np.array(batch[1], dtype=np.int64),\n",
    "                \"input_mask:0\": np.array(batch[2], dtype=np.int64),\n",
    "                \"segment_ids:0\": np.array(batch[3], dtype=np.int64)}\n",
    "        result = session.run([\"unique_ids:0\",\"unstack:0\", \"unstack:1\"], data)\n",
    "        in_batch = result[0].shape[0]\n",
    "        start_logits = [float(x) for x in result[1][0].flat]\n",
    "        end_logits = [float(x) for x in result[2][0].flat]\n",
    "        for i in range(0, in_batch):\n",
    "            unique_id = len(all_results)\n",
    "            all_results.append(RawResult(unique_id=unique_id, start_logits=start_logits,end_logits=end_logits))\n",
    "    \n",
    "    # postprocessing\n",
    "    output_dir = './output'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_prediction_file = os.path.join(output_dir, \"predictions_mobilebert_fp32.json\")\n",
    "    output_nbest_file = os.path.join(output_dir, \"nbest_predictions_mobilebert_fp32.json\")\n",
    "    write_predictions(eval_examples, extra_data, all_results,\n",
    "                    n_best_size, max_answer_length,\n",
    "                    True, output_prediction_file, output_nbest_file)\n",
    "\n",
    "    with open(input_file) as dataset_file:\n",
    "        dataset_json = json.load(dataset_file)\n",
    "        expected_version = '1.1'\n",
    "        if (dataset_json['version'] != expected_version):\n",
    "            print('Evaluation expects v-' + expected_version +\n",
    "                    ', but got dataset with v-' + dataset_json['version'],\n",
    "                    file=sys.stderr)\n",
    "        dataset = dataset_json['data']\n",
    "    with open(output_prediction_file) as prediction_file:\n",
    "        predictions = json.load(prediction_file)\n",
    "    res = evaluate(dataset, predictions)\n",
    "    return res['exact_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 13:33:06 [WARNING] Force convert framework model to neural_compressor model.\n",
      "2023-02-17 13:33:28 [INFO] Get FP32 model baseline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeArg(name='unstack:1', type='tensor(float)', shape=['unk__496', 256])\n",
      "NodeArg(name='unstack:0', type='tensor(float)', shape=['unk__497', 256])\n",
      "NodeArg(name='unique_ids:0', type='tensor(int64)', shape=['unk__498'])\n",
      "NodeArg(name='unique_ids_raw_output___9:0', type='tensor(int64)', shape=['unk__492'])\n",
      "NodeArg(name='segment_ids:0', type='tensor(int64)', shape=['unk__493', 256])\n",
      "NodeArg(name='input_mask:0', type='tensor(int64)', shape=['unk__494', 256])\n",
      "NodeArg(name='input_ids:0', type='tensor(int64)', shape=['unk__495', 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 0it [00:00, ?it/s]/tmp/ipykernel_303970/1591766422.py:13: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data = {\"unique_ids_raw_output___9:0\": np.array(batch[0], dtype=np.int64),\n",
      "eval: 12006it [13:28, 14.85it/s]\n",
      "2023-02-17 13:47:25 [INFO] Save tuning history to /home/mengniwa/notebook/nc_workspace/2023-02-17_13-22-48/./history.snapshot.\n",
      "2023-02-17 13:47:25 [INFO] FP32 baseline is: [Accuracy: 80.6717, Duration (seconds): 837.1335]\n",
      "2023-02-17 13:47:47 [INFO] |******Mixed Precision Statistics******|\n",
      "2023-02-17 13:47:47 [INFO] +-----------------------+-------+------+\n",
      "2023-02-17 13:47:47 [INFO] |        Op Type        | Total | INT8 |\n",
      "2023-02-17 13:47:47 [INFO] +-----------------------+-------+------+\n",
      "2023-02-17 13:47:47 [INFO] |         Gather        |   1   |  1   |\n",
      "2023-02-17 13:47:47 [INFO] |         MatMul        |   86  |  86  |\n",
      "2023-02-17 13:47:47 [INFO] |    DequantizeLinear   |   1   |  1   |\n",
      "2023-02-17 13:47:47 [INFO] | DynamicQuantizeLinear |   74  |  74  |\n",
      "2023-02-17 13:47:47 [INFO] +-----------------------+-------+------+\n",
      "2023-02-17 13:47:47 [INFO] Pass quantize model elapsed time: 22724.03 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeArg(name='unstack:1', type='tensor(float)', shape=['unk__496', 256])\n",
      "NodeArg(name='unstack:0', type='tensor(float)', shape=['unk__497', 256])\n",
      "NodeArg(name='unique_ids:0', type='tensor(int64)', shape=['unk__498'])\n",
      "NodeArg(name='unique_ids_raw_output___9:0', type='tensor(int64)', shape=['unk__492'])\n",
      "NodeArg(name='segment_ids:0', type='tensor(int64)', shape=['unk__493', 256])\n",
      "NodeArg(name='input_mask:0', type='tensor(int64)', shape=['unk__494', 256])\n",
      "NodeArg(name='input_ids:0', type='tensor(int64)', shape=['unk__495', 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 12006it [09:18, 21.49it/s]\n",
      "2023-02-17 13:57:34 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 80.3311|80.6717, Duration (seconds) (int8|fp32): 586.5366|837.1335], Best tune result is: [Accuracy: 80.3311, Duration (seconds): 586.5366]\n",
      "2023-02-17 13:57:34 [INFO] |***********************Tune Result Statistics**********************|\n",
      "2023-02-17 13:57:34 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2023-02-17 13:57:34 [INFO] |     Info Type      |  Baseline | Tune 1 result | Best tune result |\n",
      "2023-02-17 13:57:34 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2023-02-17 13:57:34 [INFO] |      Accuracy      |  80.6717  |    80.3311    |     80.3311      |\n",
      "2023-02-17 13:57:34 [INFO] | Duration (seconds) | 837.1335  |   586.5366    |    586.5366      |\n",
      "2023-02-17 13:57:34 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2023-02-17 13:57:34 [INFO] Save tuning history to /home/mengniwa/notebook/nc_workspace/2023-02-17_13-22-48/./history.snapshot.\n",
      "2023-02-17 13:57:34 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2023-02-17 13:57:34 [INFO] Save deploy yaml to /home/mengniwa/notebook/nc_workspace/2023-02-17_13-22-48/deploy.yaml\n"
     ]
    }
   ],
   "source": [
    "# launcher code\n",
    "\n",
    "model = onnx.load('bertsquad-12.onnx')\n",
    "input_file = 'dev-v1.1.json'\n",
    "eval_examples = read_squad_examples(input_file='dev-v1.1.json')\n",
    "\n",
    "vocab_file = os.path.join('uncased_L-12_H-768_A-12', 'vocab.txt')\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=True)\n",
    "input_ids, input_mask, segment_ids, extra_data = convert_examples_to_features(eval_examples, tokenizer, \n",
    "                                                                            max_seq_length, doc_stride, max_query_length)\n",
    "dataset = squadDataset(eval_examples, input_ids, input_mask, segment_ids, 1) \n",
    "eval_dataloader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "def eval_func(model):\n",
    "    return evaluate_squad(model, eval_dataloader, input_ids, eval_examples, extra_data, input_file)\n",
    "\n",
    "from neural_compressor import quantization, PostTrainingQuantConfig\n",
    "config = PostTrainingQuantConfig(approach='dynamic',)\n",
    "q_model = quantization.fit(model, \n",
    "                           config,\n",
    "                           eval_func=eval_func)\n",
    "q_model.save('bert-int8.onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8af6e5486e841295e99d7ef897e20658bc80db4d5a8a0bef91afa6b4efc15c34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
